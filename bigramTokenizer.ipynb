{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP on ARES"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (3.3.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (8.0.15)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (65.6.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (1.0.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (0.7.7)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (0.9.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (22.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install spacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7100\\3486703057.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbigrams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenize_bigrams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Documentación proceso multipago bancario ajuste estructura archivo consignantes\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7100\\3486703057.py\u001b[0m in \u001b[0;36mtokenize_bigrams\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtokenize_bigrams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Process the text using the spaCy pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Extract the lemmatized tokens from the processed text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemma_\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stop\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_punct\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the function to tokenize a string into bigrams\n",
    "def tokenize_bigrams(text):\n",
    "    # Process the text using the spaCy pipeline\n",
    "    doc = nlp(text)\n",
    "    # Extract the lemmatized tokens from the processed text\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "    # Combine adjacent pairs of tokens into bigrams\n",
    "    bigrams = [f\"{tokens[i]} {tokens[i+1]}\" for i in range(len(tokens)-1)]\n",
    "    return bigrams\n",
    "\n",
    "print(tokenize_bigrams(\"Documentación proceso multipago bancario ajuste estructura archivo consignantes\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARES Activities Dataset and Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DESCRIPCION</th>\n",
       "      <th>CODIGO_ETAPA</th>\n",
       "      <th>DURACION_HORAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vacaciones</td>\n",
       "      <td>VAC</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vacaciones</td>\n",
       "      <td>VAC</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Documentación proceso multipago bancario ajust...</td>\n",
       "      <td>COCOD</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Documentación proceso acumulación pisos y paso...</td>\n",
       "      <td>COCOD</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Documentación proceso acumulación pisos y cont...</td>\n",
       "      <td>COCOD</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Vacaciones</td>\n",
       "      <td>VAC</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vacaciones</td>\n",
       "      <td>VAC</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Vacaciones</td>\n",
       "      <td>VAC</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vacaciones</td>\n",
       "      <td>VAC</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vacaciones</td>\n",
       "      <td>VAC</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         DESCRIPCION CODIGO_ETAPA  \\\n",
       "0                                         Vacaciones          VAC   \n",
       "1                                         Vacaciones          VAC   \n",
       "2  Documentación proceso multipago bancario ajust...        COCOD   \n",
       "3  Documentación proceso acumulación pisos y paso...        COCOD   \n",
       "4  Documentación proceso acumulación pisos y cont...        COCOD   \n",
       "5                                         Vacaciones          VAC   \n",
       "6                                         Vacaciones          VAC   \n",
       "7                                         Vacaciones          VAC   \n",
       "8                                         Vacaciones          VAC   \n",
       "9                                         Vacaciones          VAC   \n",
       "\n",
       "   DURACION_HORAS  \n",
       "0             8.0  \n",
       "1             8.0  \n",
       "2             3.0  \n",
       "3             3.0  \n",
       "4             2.0  \n",
       "5             8.0  \n",
       "6             8.0  \n",
       "7             8.0  \n",
       "8             8.0  \n",
       "9             8.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"ARES2_EJECUCION_ACTIVIDADES.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                                              DESCRIPCION CODIGO_ETAPA  \\\n",
       "0                                             Vacaciones          VAC   \n",
       "1                                             Vacaciones          VAC   \n",
       "2      Documentación proceso multipago bancario ajust...        COCOD   \n",
       "3      Documentación proceso acumulación pisos y paso...        COCOD   \n",
       "4      Documentación proceso acumulación pisos y cont...        COCOD   \n",
       "...                                                  ...          ...   \n",
       "52851  Reunión daily, Documentando el código desarrol...        COCOD   \n",
       "52852  Generando los test unitarios a los servicios y...        COCOD   \n",
       "52853  Homologando las colecciones de postman, optimi...        COCOD   \n",
       "52854  Validación de los datos de parametrización e i...        TRCON   \n",
       "52855  Apoyo al equipo de trabajo con las tareas del ...        DIAPL   \n",
       "\n",
       "       DURACION_HORAS  \n",
       "0                 8.0  \n",
       "1                 8.0  \n",
       "2                 3.0  \n",
       "3                 3.0  \n",
       "4                 2.0  \n",
       "...               ...  \n",
       "52851             3.0  \n",
       "52852             2.0  \n",
       "52853             3.0  \n",
       "52854             2.0  \n",
       "52855             2.0  \n",
       "\n",
       "[52856 rows x 3 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CODIGO_ETAPA'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DESCRIPCION', 'CODIGO_ETAPA', 'DURACION_HORAS'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter the table in order to have only data from the some codes\n",
    "codes = ['APSEG', 'PRSIS', 'ASEJE', 'COAJU']\n",
    "df1=df[df[\"CODIGO_ETAPA\"].isin(codes)]\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DESCRIPCION</th>\n",
       "      <th>CODIGO_ETAPA</th>\n",
       "      <th>DURACION_HORAS</th>\n",
       "      <th>bigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Validación programas formatos DIAN</td>\n",
       "      <td>APSEG</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{programa formato, validación programa, format...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Defectos priorizados CTO</td>\n",
       "      <td>APSEG</td>\n",
       "      <td>5.00</td>\n",
       "      <td>{priorizado CTO, Defectos priorizado}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Daily CTO bugs priorizados Fase II y Fase I</td>\n",
       "      <td>APSEG</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{bugs priorizado, Daily CTO, Fase II, Fase I, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DAILY</td>\n",
       "      <td>PRSIS</td>\n",
       "      <td>0.50</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Elaboración del manual de usuario</td>\n",
       "      <td>PRSIS</td>\n",
       "      <td>0.50</td>\n",
       "      <td>{manual usuario, Elaboración manual}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52799</th>\n",
       "      <td>QA Ciclo 1</td>\n",
       "      <td>PRSIS</td>\n",
       "      <td>2.00</td>\n",
       "      <td>{Ciclo 1, qa Ciclo}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52800</th>\n",
       "      <td>QA Ciclo 1</td>\n",
       "      <td>PRSIS</td>\n",
       "      <td>2.00</td>\n",
       "      <td>{Ciclo 1, qa Ciclo}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52808</th>\n",
       "      <td>Daily</td>\n",
       "      <td>APSEG</td>\n",
       "      <td>0.50</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52812</th>\n",
       "      <td>Apoyo a krizz con los reportes de OBIEE</td>\n",
       "      <td>PRSIS</td>\n",
       "      <td>3.00</td>\n",
       "      <td>{krizz report, apoyo krizz, report OBIEE}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52813</th>\n",
       "      <td>Validación del requerimiento de master debit m...</td>\n",
       "      <td>PRSIS</td>\n",
       "      <td>2.00</td>\n",
       "      <td>{debit moneysend, master debit, requerimiento ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6361 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             DESCRIPCION CODIGO_ETAPA  \\\n",
       "10                    Validación programas formatos DIAN        APSEG   \n",
       "11                              Defectos priorizados CTO        APSEG   \n",
       "14           Daily CTO bugs priorizados Fase II y Fase I        APSEG   \n",
       "17                                                 DAILY        PRSIS   \n",
       "18                     Elaboración del manual de usuario        PRSIS   \n",
       "...                                                  ...          ...   \n",
       "52799                                         QA Ciclo 1        PRSIS   \n",
       "52800                                         QA Ciclo 1        PRSIS   \n",
       "52808                                              Daily        APSEG   \n",
       "52812            Apoyo a krizz con los reportes de OBIEE        PRSIS   \n",
       "52813  Validación del requerimiento de master debit m...        PRSIS   \n",
       "\n",
       "       DURACION_HORAS                                            bigrams  \n",
       "10               0.75  {programa formato, validación programa, format...  \n",
       "11               5.00              {priorizado CTO, Defectos priorizado}  \n",
       "14               0.25  {bugs priorizado, Daily CTO, Fase II, Fase I, ...  \n",
       "17               0.50                                                 {}  \n",
       "18               0.50               {manual usuario, Elaboración manual}  \n",
       "...               ...                                                ...  \n",
       "52799            2.00                                {Ciclo 1, qa Ciclo}  \n",
       "52800            2.00                                {Ciclo 1, qa Ciclo}  \n",
       "52808            0.50                                                 {}  \n",
       "52812            3.00          {krizz report, apoyo krizz, report OBIEE}  \n",
       "52813            2.00  {debit moneysend, master debit, requerimiento ...  \n",
       "\n",
       "[6361 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load of Trained Language Model in Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting es-core-news-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.5.0/es_core_news_sm-3.5.0-py3-none-any.whl (12.9 MB)\n",
      "     ---------------------------------------- 12.9/12.9 MB 3.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from es-core-news-sm==3.5.0) (3.5.1)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (21.3)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (8.1.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (63.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.28.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.21.5)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.11.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (5.2.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.10.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (4.64.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (4.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2022.9.14)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\sferreira\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.0.1)\n",
      "Installing collected packages: es-core-news-sm\n",
      "Successfully installed es-core-news-sm-3.5.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "# Load the Spanish language model\n",
    "!python -m spacy download es_core_news_sm\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard Similarity per CÓDIGO_ETAPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODIGO_ETAPA: APSEG - Jaccard similarity: 0.00\n",
      "CODIGO_ETAPA: PRSIS - Jaccard similarity: 0.00\n",
      "CODIGO_ETAPA: ASEJE - Jaccard similarity: 0.00\n",
      "CODIGO_ETAPA: COAJU - Jaccard similarity: 0.00\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define the function to tokenize a string into bigrams\n",
    "def tokenize_bigrams(text):\n",
    "    # Process the text using the spaCy pipeline\n",
    "    doc = nlp(text)\n",
    "    # Extract the lemmatized tokens from the processed text\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "    # Combine adjacent pairs of tokens into bigrams\n",
    "    bigrams = [f\"{tokens[i]} {tokens[i+1]}\" for i in range(len(tokens)-1)]\n",
    "    return set(bigrams)\n",
    "\n",
    "\n",
    "# Group the descriptions by unique code in 'CODIGO_ETAPA' and tokenize them into sets of bigrams\n",
    "code_sets = {}\n",
    "for code in df1['CODIGO_ETAPA'].unique():\n",
    "    code_set = set()\n",
    "    for description in df1.loc[df1['CODIGO_ETAPA'] == code, 'DESCRIPCION']:\n",
    "        code_set.update(tokenize_bigrams(description))\n",
    "    code_sets[code] = code_set\n",
    "\n",
    "# Get the user input\n",
    "prompt = input(\"Please enter a description: \")\n",
    "prompt_set = tokenize_bigrams(prompt)\n",
    "\n",
    "# Compute the Jaccard similarity between the sets and the prompt\n",
    "similarities = {}\n",
    "for code, code_set in code_sets.items():\n",
    "    jaccard_sim = len(prompt_set.intersection(code_set)) / len(prompt_set.union(code_set))\n",
    "    similarities[code] = jaccard_sim\n",
    "\n",
    "# Print the similarity scores in descending order\n",
    "for code, sim in sorted(similarities.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"CODIGO_ETAPA: {code} - Jaccard similarity: {sim:.2f}\")\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Engine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is filtered by codes APSEG, PRSIS, ASEJE, COAJU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sferreira\\AppData\\Local\\Temp\\ipykernel_7100\\1799512459.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[\"bigrams\"] = df1[\"DESCRIPCION\"].apply(lambda x: set(tokenize_bigrams(x)))\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Define the function to tokenize a string into bigrams\n",
    "def tokenize_bigrams(text):\n",
    "    # Process the text using the spaCy pipeline\n",
    "    doc = nlp(text)\n",
    "    # Extract the lemmatized tokens from the processed text\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "    # Combine adjacent pairs of tokens into bigrams\n",
    "    bigrams = [f\"{tokens[i]} {tokens[i+1]}\" for i in range(len(tokens)-1)]\n",
    "    return bigrams\n",
    "\n",
    "# Tokenize the 'DESCRIPCION' column into bigrams and create a set of unique bigrams for each row\n",
    "df1[\"bigrams\"] = df1[\"DESCRIPCION\"].apply(lambda x: set(tokenize_bigrams(x)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lineas de prueba\n",
    "\n",
    "* QA Ciclo 1\n",
    "* - Pruebas de regresión y cierre de bugs\n",
    "* HU módulo \n",
    "* Desarrollo actividades para ajustes segun archivo del"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User's input: manual usuario\n",
      "The most similar description for this input is: Actualización manual de usuario\n",
      "The recommended CODIGO_ETAPA for this description is: PRSIS\n"
     ]
    }
   ],
   "source": [
    "# Prompt the user for a description\n",
    "user_description = input(\"Please enter a description: \")\n",
    "\n",
    "# Tokenize the user description into bigrams\n",
    "user_bigrams = set(tokenize_bigrams(user_description))\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(), lowercase=False, use_idf=True)\n",
    "corpus = [\" \".join(row) for row in df1[\"bigrams\"].values]\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X = X.log1p()\n",
    "\n",
    "\n",
    "\n",
    "# Compute the cosine similarity between the user bigrams and the bigrams in the dataset\n",
    "user = vectorizer.transform([\" \".join(user_bigrams)])\n",
    "similarity_scores = cosine_similarity(user, X)\n",
    "\n",
    "# Get the index of the row with the highest similarity score\n",
    "most_similar_index = similarity_scores.argmax()\n",
    "\n",
    "# Get the corresponding DESCRIPCION of the highest similarity score\n",
    "mostSimilarDescripcion = df1.iloc[most_similar_index][\"DESCRIPCION\"]\n",
    "\n",
    "# Get the corresponding value of the 'CODIGO_ETAPA' column\n",
    "recommended_etapa = df1.iloc[most_similar_index][\"CODIGO_ETAPA\"]\n",
    "\n",
    "# Print the most similar DESCRIPCION and the recommended CODIGO_ETAPA\n",
    "print(f'User\\'s input: {user_description}')\n",
    "print(f\"The most similar description for this input is: {mostSimilarDescripcion}\")\n",
    "print(f\"The recommended CODIGO_ETAPA for this description is: {recommended_etapa}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "Input description: DAILY\n"
     ]
    }
   ],
   "source": [
    "# Choose a random row from the DataFrame\n",
    "row = df1.sample()\n",
    "\n",
    "# Get the actual CODIGO_ETAPA for this row\n",
    "actual_etapa = row[\"CODIGO_ETAPA\"].values[0]\n",
    "\n",
    "# Get the DESCRIPCION for this row\n",
    "descripcion = row[\"DESCRIPCION\"].values[0]\n",
    "\n",
    "# Compute the recommended CODIGO_ETAPA for this row using your code\n",
    "user_bigrams = set(tokenize_bigrams(descripcion))\n",
    "user = vectorizer.transform([\" \".join(user_bigrams)])\n",
    "similarity_scores = cosine_similarity(user, X)\n",
    "most_similar_index = similarity_scores.argmax()\n",
    "recommended_etapa = df1.iloc[most_similar_index][\"CODIGO_ETAPA\"]\n",
    "\n",
    "# Print the results\n",
    "print(f\"Actual CODIGO_ETAPA: {actual_etapa}\")\n",
    "print(f\"Recommended CODIGO_ETAPA: {recommended_etapa}\")\n",
    "print(f\"Input description: {descripcion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of correct recommendations: 98.27071215217732%\n"
     ]
    }
   ],
   "source": [
    "# Initialize a counter for the number of correct recommendations\n",
    "num_correct = 0\n",
    "\n",
    "# Loop through each row in the DataFrame\n",
    "for index, row in df1.iterrows():\n",
    "    # Get the actual CODIGO_ETAPA and DESCRIPCION for this row\n",
    "    actual_etapa = row[\"CODIGO_ETAPA\"]\n",
    "    descripcion = row[\"DESCRIPCION\"]\n",
    "    \n",
    "    # Compute the recommended CODIGO_ETAPA for this row using your code\n",
    "    user_bigrams = set(tokenize_bigrams(descripcion))\n",
    "    user = vectorizer.transform([\" \".join(user_bigrams)])\n",
    "    similarity_scores = cosine_similarity(user, X)\n",
    "    most_similar_index = similarity_scores.argmax()\n",
    "    recommended_etapa = df1.iloc[most_similar_index][\"CODIGO_ETAPA\"]\n",
    "    \n",
    "    # Check if the recommended CODIGO_ETAPA is equal to the actual CODIGO_ETAPA\n",
    "    if recommended_etapa == actual_etapa:\n",
    "        num_correct += 1\n",
    "\n",
    "# Calculate the percentage of correct recommendations\n",
    "percent_correct = (num_correct / len(df1)) * 100\n",
    "print(f\"Percentage of correct recommendations: {percent_correct}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description: DAILY\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: DAILY\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: DAILY\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Reunión de seguimiento diario\n",
      "Actual CODIGO_ETAPA: APSEG\n",
      "Recommended CODIGO_ETAPA: PRSIS\n",
      "\n",
      "Description: Grooming\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: DAILY\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Pendiente\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Pendiente\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Pendiente\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: DAILY\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Reunión de seguimiento diario\n",
      "Actual CODIGO_ETAPA: APSEG\n",
      "Recommended CODIGO_ETAPA: PRSIS\n",
      "\n",
      "Description: Pendiente\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Pendiente\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Pendiente\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: DAILY\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: HU_07_Listado_solicitudes_gestor.\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: HU_07_Listado_solicitudes_gestor.\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: DAILY\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Task:\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Task:\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Daily\n",
      "Actual CODIGO_ETAPA: ASEJE\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: DAILY\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: DAILY\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Reunión de seguimiento diario\n",
      "Actual CODIGO_ETAPA: APSEG\n",
      "Recommended CODIGO_ETAPA: PRSIS\n",
      "\n",
      "Description: DAILY\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Daily\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Compensatorio\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Compensatorio\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Compensatorio\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Daily\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Compensatorio\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Compensatorio\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Compensatorio\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Compensatorio\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Daily\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Daily\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Daily\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Dayly\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Día compensatorio\n",
      "Actual CODIGO_ETAPA: ASEJE\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Día compensatorio\n",
      "Actual CODIGO_ETAPA: ASEJE\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Día compensatorio\n",
      "Actual CODIGO_ETAPA: ASEJE\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: HU_004_Recibir_información_de_cambios_en_la_solicitud.\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: daily\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Daily\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Daily\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: soporte\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Encuesta\n",
      "Actual CODIGO_ETAPA: ASEJE\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: HU_10_Detalle_solicitudes_Tecnico.\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: HU_10_Detalle_solicitudes_Tecnico.\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: HU_10_Detalle_solicitudes_Tecnico.\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: encuesta.\n",
      "Actual CODIGO_ETAPA: ASEJE\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Aplicación encuesta psicosocial\n",
      "Actual CODIGO_ETAPA: APSEG\n",
      "Recommended CODIGO_ETAPA: ASEJE\n",
      "\n",
      "Description: Encuesta\n",
      "Actual CODIGO_ETAPA: ASEJE\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Encuesta\n",
      "Actual CODIGO_ETAPA: ASEJE\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Aplicación encuesta Psicosocial\n",
      "Actual CODIGO_ETAPA: APSEG\n",
      "Recommended CODIGO_ETAPA: ASEJE\n",
      "\n",
      "Description: HU_02_Creación_de_solicitud.\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Encuesta \n",
      "Actual CODIGO_ETAPA: ASEJE\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Encuesta\n",
      "Actual CODIGO_ETAPA: ASEJE\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Diligenciamiento encuesta psicosocial\n",
      "Actual CODIGO_ETAPA: APSEG\n",
      "Recommended CODIGO_ETAPA: ASEJE\n",
      "\n",
      "Description: Congiuración Ambiente Drupal\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: ASEJE\n",
      "\n",
      "Description: Congiuración Ambiente Drupal\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: ASEJE\n",
      "\n",
      "Description: Congiuración Ambiente Drupal\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: ASEJE\n",
      "\n",
      "Description: Encuesta\n",
      "Actual CODIGO_ETAPA: ASEJE\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Encuesta\n",
      "Actual CODIGO_ETAPA: ASEJE\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Congiuración Ambiente Drupal\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: ASEJE\n",
      "\n",
      "Description: Ir a Bolívar\n",
      "Actual CODIGO_ETAPA: ASEJE\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Daily Neps\n",
      "Actual CODIGO_ETAPA: ASEJE\n",
      "Recommended CODIGO_ETAPA: COAJU\n",
      "\n",
      "Description: Daily Neps\n",
      "Actual CODIGO_ETAPA: ASEJE\n",
      "Recommended CODIGO_ETAPA: COAJU\n",
      "\n",
      "Description: planing\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: pruebas\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: pruebas\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: pruebas\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Daily\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: PROV-958\n",
      "Actual CODIGO_ETAPA: ASEJE\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: PROV-958\n",
      "Actual CODIGO_ETAPA: ASEJE\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Daily\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: pruebas\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: pruebas\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: pruebas\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: pruebas\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: pruebas\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: PROV-958\n",
      "Actual CODIGO_ETAPA: ASEJE\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: PROV-958\n",
      "Actual CODIGO_ETAPA: ASEJE\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: PROV-958\n",
      "Actual CODIGO_ETAPA: ASEJE\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: PROV-958\n",
      "Actual CODIGO_ETAPA: ASEJE\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Compensatorio\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Compensatorio\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: PROV-958\n",
      "Actual CODIGO_ETAPA: ASEJE\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: PROV-958\n",
      "Actual CODIGO_ETAPA: ASEJE\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Compensatorio\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Compensatorio\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: PROV-958\n",
      "Actual CODIGO_ETAPA: ASEJE\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: PROV-958\n",
      "Actual CODIGO_ETAPA: ASEJE\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: daily\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: PROV-958\n",
      "Actual CODIGO_ETAPA: ASEJE\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: daily\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Daily\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: nnnnnnnnnnn\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: daily\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: daily\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Daily\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: daily\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: daily\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: DAILY\n",
      "Actual CODIGO_ETAPA: PRSIS\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: daily\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Pruebas\n",
      "Actual CODIGO_ETAPA: ASEJE\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: Pruebas\n",
      "Actual CODIGO_ETAPA: ASEJE\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: HU_10_Detalle_solicitudes_Tecnico.\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: HU_10_Detalle_solicitudes_Tecnico\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Description: HU_10_Detalle_solicitudes_Tecnico.\n",
      "Actual CODIGO_ETAPA: COAJU\n",
      "Recommended CODIGO_ETAPA: APSEG\n",
      "\n",
      "Percentage of correct recommendations: 98.27071215217732%\n",
      "Amount of correct recomendations: 6251\n",
      "Total recomendations: 6361\n"
     ]
    }
   ],
   "source": [
    "# Initialize a counter for the number of correct recommendations\n",
    "num_correct = 0\n",
    "\n",
    "# Loop through each row in the DataFrame\n",
    "for index, row in df1.iterrows():\n",
    "    # Get the actual CODIGO_ETAPA and DESCRIPCION for this row\n",
    "    actual_etapa = row[\"CODIGO_ETAPA\"]\n",
    "    descripcion = row[\"DESCRIPCION\"]\n",
    "    \n",
    "    # Compute the recommended CODIGO_ETAPA for this row using your code\n",
    "    user_bigrams = set(tokenize_bigrams(descripcion))\n",
    "    user = vectorizer.transform([\" \".join(user_bigrams)])\n",
    "    similarity_scores = cosine_similarity(user, X)\n",
    "    most_similar_index = similarity_scores.argmax()\n",
    "    recommended_etapa = df1.iloc[most_similar_index][\"CODIGO_ETAPA\"]\n",
    "    \n",
    "    # Check if the recommended CODIGO_ETAPA is equal to the actual CODIGO_ETAPA\n",
    "    if recommended_etapa == actual_etapa:\n",
    "        num_correct += 1\n",
    "    else:\n",
    "        # Print the description, actual_etapa, and recommended_etapa when they are not the same\n",
    "        print(f\"Description: {descripcion}\")\n",
    "        print(f\"Actual CODIGO_ETAPA: {actual_etapa}\")\n",
    "        print(f\"Recommended CODIGO_ETAPA: {recommended_etapa}\\n\")\n",
    "\n",
    "# Calculate the percentage of correct recommendations\n",
    "percent_correct = (num_correct / len(df1)) * 100\n",
    "print(f\"Percentage of correct recommendations: {percent_correct}%\")\n",
    "print(f\"Amount of correct recomendations: {num_correct}\")\n",
    "print(f\"Total recomendations: {len(df1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of correct recommendations using only the first half of the description: 74.50086464392392%\n",
      "Amount of correct recomendations: 4739\n",
      "Total recomendations: 6361\n"
     ]
    }
   ],
   "source": [
    "# Initialize a counter for the number of correct recommendations\n",
    "num_correct = 0\n",
    "\n",
    "# Loop through each row in the DataFrame\n",
    "for index, row in df1.iterrows():\n",
    "    # Get the actual CODIGO_ETAPA and DESCRIPCION for this row\n",
    "    actual_etapa = row[\"CODIGO_ETAPA\"]\n",
    "    descripcion = row[\"DESCRIPCION\"]\n",
    "    \n",
    "    # Use only the first half of the description\n",
    "    descripcion_half = descripcion[:int(len(descripcion)/2)]\n",
    "    \n",
    "    # Compute the recommended CODIGO_ETAPA for this row using your code\n",
    "    user_bigrams = set(tokenize_bigrams(descripcion_half))\n",
    "    user = vectorizer.transform([\" \".join(user_bigrams)])\n",
    "    similarity_scores = cosine_similarity(user, X)\n",
    "    most_similar_index = similarity_scores.argmax()\n",
    "    recommended_etapa = df1.iloc[most_similar_index][\"CODIGO_ETAPA\"]\n",
    "    \n",
    "    # Check if the recommended CODIGO_ETAPA is equal to the actual CODIGO_ETAPA\n",
    "    if recommended_etapa == actual_etapa:\n",
    "        num_correct += 1\n",
    "\n",
    "# Calculate the percentage of correct recommendations\n",
    "percent_correct = (num_correct / len(df1)) * 100\n",
    "print(f\"Percentage of correct recommendations using only the first half of the description: {percent_correct}%\")\n",
    "print(f\"Amount of correct recomendations: {num_correct}\")\n",
    "print(f\"Total recomendations: {len(df1)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"df1.csv\", index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works very well if  searched for an exact descrption, it fails if that description is in several etapas.\n",
    "if the description is only half of the original the it will work most of the time but fail if half of the description is to short "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "equinox_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
