{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP on ARES"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (3.3.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (8.0.15)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (65.6.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (1.0.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (0.7.7)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (0.9.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (22.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install spacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Documentación proceso', 'proceso multipago', 'multipago bancario', 'bancario ajuste', 'ajuste estructura', 'estructura archivo', 'archivo consignant']\n"
     ]
    }
   ],
   "source": [
    "# Define the function to tokenize a string into bigrams\n",
    "def tokenize_bigrams(text):\n",
    "    # Process the text using the spaCy pipeline\n",
    "    doc = nlp(text)\n",
    "    # Extract the lemmatized tokens from the processed text\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "    # Combine adjacent pairs of tokens into bigrams\n",
    "    bigrams = [f\"{tokens[i]} {tokens[i+1]}\" for i in range(len(tokens)-1)]\n",
    "    return bigrams\n",
    "\n",
    "print(tokenize_bigrams(\"Documentación proceso multipago bancario ajuste estructura archivo consignantes\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARES Activities Dataset and Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DESCRIPCION</th>\n",
       "      <th>CODIGO_ETAPA</th>\n",
       "      <th>DURACION_HORAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vacaciones</td>\n",
       "      <td>VAC</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vacaciones</td>\n",
       "      <td>VAC</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Documentación proceso multipago bancario ajust...</td>\n",
       "      <td>COCOD</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Documentación proceso acumulación pisos y paso...</td>\n",
       "      <td>COCOD</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Documentación proceso acumulación pisos y cont...</td>\n",
       "      <td>COCOD</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Vacaciones</td>\n",
       "      <td>VAC</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vacaciones</td>\n",
       "      <td>VAC</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Vacaciones</td>\n",
       "      <td>VAC</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vacaciones</td>\n",
       "      <td>VAC</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vacaciones</td>\n",
       "      <td>VAC</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         DESCRIPCION CODIGO_ETAPA  \\\n",
       "0                                         Vacaciones          VAC   \n",
       "1                                         Vacaciones          VAC   \n",
       "2  Documentación proceso multipago bancario ajust...        COCOD   \n",
       "3  Documentación proceso acumulación pisos y paso...        COCOD   \n",
       "4  Documentación proceso acumulación pisos y cont...        COCOD   \n",
       "5                                         Vacaciones          VAC   \n",
       "6                                         Vacaciones          VAC   \n",
       "7                                         Vacaciones          VAC   \n",
       "8                                         Vacaciones          VAC   \n",
       "9                                         Vacaciones          VAC   \n",
       "\n",
       "   DURACION_HORAS  \n",
       "0             8.0  \n",
       "1             8.0  \n",
       "2             3.0  \n",
       "3             3.0  \n",
       "4             2.0  \n",
       "5             8.0  \n",
       "6             8.0  \n",
       "7             8.0  \n",
       "8             8.0  \n",
       "9             8.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"ARES2_EJECUCION_ACTIVIDADES.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                                              DESCRIPCION CODIGO_ETAPA  \\\n",
       "0                                             Vacaciones          VAC   \n",
       "1                                             Vacaciones          VAC   \n",
       "2      Documentación proceso multipago bancario ajust...        COCOD   \n",
       "3      Documentación proceso acumulación pisos y paso...        COCOD   \n",
       "4      Documentación proceso acumulación pisos y cont...        COCOD   \n",
       "...                                                  ...          ...   \n",
       "52851  Reunión daily, Documentando el código desarrol...        COCOD   \n",
       "52852  Generando los test unitarios a los servicios y...        COCOD   \n",
       "52853  Homologando las colecciones de postman, optimi...        COCOD   \n",
       "52854  Validación de los datos de parametrización e i...        TRCON   \n",
       "52855  Apoyo al equipo de trabajo con las tareas del ...        DIAPL   \n",
       "\n",
       "       DURACION_HORAS  \n",
       "0                 8.0  \n",
       "1                 8.0  \n",
       "2                 3.0  \n",
       "3                 3.0  \n",
       "4                 2.0  \n",
       "...               ...  \n",
       "52851             3.0  \n",
       "52852             2.0  \n",
       "52853             3.0  \n",
       "52854             2.0  \n",
       "52855             2.0  \n",
       "\n",
       "[52856 rows x 3 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CODIGO_ETAPA'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DESCRIPCION', 'CODIGO_ETAPA', 'DURACION_HORAS'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter the table in order to have only data from the some codes\n",
    "codes = ['APSEG', 'PRSIS', 'ASEJE', 'COAJU']\n",
    "df1=df[df[\"CODIGO_ETAPA\"].isin(codes)]\n",
    "df1.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load of Trained Language Model in Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting es-core-news-sm==3.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.3.0/es_core_news_sm-3.3.0-py3-none-any.whl (12.9 MB)\n",
      "     --------------------------------------- 12.9/12.9 MB 11.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from es-core-news-sm==3.3.0) (3.3.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (1.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (4.65.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (65.6.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (3.0.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (2.4.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (2.28.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (8.0.15)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (1.0.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (2.0.7)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (22.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (0.9.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (0.4.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (0.7.7)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (1.0.7)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (1.26.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\miguel granados c\\anaconda3\\envs\\equinox_base\\lib\\site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (2.1.1)\n",
      "Installing collected packages: es-core-news-sm\n",
      "Successfully installed es-core-news-sm-3.3.0\n",
      "✔ Download and installation successful\n",
      "You can now load the package via spacy.load('es_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "# Load the Spanish language model\n",
    "!python -m spacy download es_core_news_sm\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard Similarity per CÓDIGO_ETAPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODIGO_ETAPA: COAJU - Jaccard similarity: 0.00\n",
      "CODIGO_ETAPA: PRSIS - Jaccard similarity: 0.00\n",
      "CODIGO_ETAPA: APSEG - Jaccard similarity: 0.00\n",
      "CODIGO_ETAPA: ASEJE - Jaccard similarity: 0.00\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define the function to tokenize a string into bigrams\n",
    "def tokenize_bigrams(text):\n",
    "    # Process the text using the spaCy pipeline\n",
    "    doc = nlp(text)\n",
    "    # Extract the lemmatized tokens from the processed text\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "    # Combine adjacent pairs of tokens into bigrams\n",
    "    bigrams = [f\"{tokens[i]} {tokens[i+1]}\" for i in range(len(tokens)-1)]\n",
    "    return set(bigrams)\n",
    "\n",
    "\n",
    "# Group the descriptions by unique code in 'CODIGO_ETAPA' and tokenize them into sets of bigrams\n",
    "code_sets = {}\n",
    "for code in df1['CODIGO_ETAPA'].unique():\n",
    "    code_set = set()\n",
    "    for description in df1.loc[df1['CODIGO_ETAPA'] == code, 'DESCRIPCION']:\n",
    "        code_set.update(tokenize_bigrams(description))\n",
    "    code_sets[code] = code_set\n",
    "\n",
    "# Get the user input\n",
    "prompt = input(\"Please enter a description: \")\n",
    "prompt_set = tokenize_bigrams(prompt)\n",
    "\n",
    "# Compute the Jaccard similarity between the sets and the prompt\n",
    "similarities = {}\n",
    "for code, code_set in code_sets.items():\n",
    "    jaccard_sim = len(prompt_set.intersection(code_set)) / len(prompt_set.union(code_set))\n",
    "    similarities[code] = jaccard_sim\n",
    "\n",
    "# Print the similarity scores in descending order\n",
    "for code, sim in sorted(similarities.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"CODIGO_ETAPA: {code} - Jaccard similarity: {sim:.2f}\")\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Engine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is filtered by codes APSEG, PRSIS, ASEJE, COAJU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miguel Granados C\\AppData\\Local\\Temp\\ipykernel_18928\\1799512459.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[\"bigrams\"] = df1[\"DESCRIPCION\"].apply(lambda x: set(tokenize_bigrams(x)))\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Define the function to tokenize a string into bigrams\n",
    "def tokenize_bigrams(text):\n",
    "    # Process the text using the spaCy pipeline\n",
    "    doc = nlp(text)\n",
    "    # Extract the lemmatized tokens from the processed text\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "    # Combine adjacent pairs of tokens into bigrams\n",
    "    bigrams = [f\"{tokens[i]} {tokens[i+1]}\" for i in range(len(tokens)-1)]\n",
    "    return bigrams\n",
    "\n",
    "# Tokenize the 'DESCRIPCION' column into bigrams and create a set of unique bigrams for each row\n",
    "df1[\"bigrams\"] = df1[\"DESCRIPCION\"].apply(lambda x: set(tokenize_bigrams(x)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lineas de prueba\n",
    "\n",
    "* QA Ciclo 1\n",
    "* - Pruebas de regresión y cierre de bugs\n",
    "* HU módulo \n",
    "* Desarrollo actividades para ajustes segun archivo del"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User's input: Desarrollo actividades para ajustes segun archivo del\n",
      "The most similar description for this input is: Desarrollo actividades para ajustes segun archivo del cliente\n",
      "The recommended CODIGO_ETAPA for this description is: COAJU\n"
     ]
    }
   ],
   "source": [
    "# Prompt the user for a description\n",
    "user_description = input(\"Please enter a description: \")\n",
    "\n",
    "# Tokenize the user description into bigrams\n",
    "user_bigrams = set(tokenize_bigrams(user_description))\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(), lowercase=False, use_idf=True)\n",
    "corpus = [\" \".join(row) for row in df1[\"bigrams\"].values]\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X = X.log1p()\n",
    "\n",
    "\n",
    "\n",
    "# Compute the cosine similarity between the user bigrams and the bigrams in the dataset\n",
    "user = vectorizer.transform([\" \".join(user_bigrams)])\n",
    "similarity_scores = cosine_similarity(user, X)\n",
    "\n",
    "# Get the index of the row with the highest similarity score\n",
    "most_similar_index = similarity_scores.argmax()\n",
    "\n",
    "# Get the corresponding DESCRIPCION of the highest similarity score\n",
    "mostSimilarDescripcion = df1.iloc[most_similar_index][\"DESCRIPCION\"]\n",
    "\n",
    "# Get the corresponding value of the 'CODIGO_ETAPA' column\n",
    "recommended_etapa = df1.iloc[most_similar_index][\"CODIGO_ETAPA\"]\n",
    "\n",
    "# Print the most similar DESCRIPCION and the recommended CODIGO_ETAPA\n",
    "print(f'User\\'s input: {user_description}')\n",
    "print(f\"The most similar description for this input is: {mostSimilarDescripcion}\")\n",
    "print(f\"The recommended CODIGO_ETAPA for this description is: {recommended_etapa}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "equinox_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
